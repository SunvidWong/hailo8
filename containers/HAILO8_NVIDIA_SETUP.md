# Hailo8 + NVIDIA AIåŠ é€ŸæœåŠ¡éƒ¨ç½²æŒ‡å—

## ğŸ“‹ éƒ¨ç½²é…ç½®æ–‡ä»¶

ä½¿ç”¨æ ‡å‡†çš„Docker Composeæ ¼å¼ï¼Œæä¾›Hailo8å’ŒNVIDIAåŒç¡¬ä»¶AIæ¨ç†åŠ é€ŸæœåŠ¡ã€‚

### ğŸš€ å¿«é€Ÿéƒ¨ç½²

```bash
# å¯åŠ¨AIåŠ é€ŸæœåŠ¡
docker-compose -f docker-compose.hailo8-nvidia.yml up -d

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
docker-compose -f docker-compose.hailo8-nvidia.yml ps

# æŸ¥çœ‹æ—¥å¿—
docker-compose -f docker-compose.hailo8-nvidia.yml logs -f hailo8-ai
```

## ğŸ”§ é…ç½®è¯´æ˜

### æœåŠ¡ç»„ä»¶

1. **hailo8-ai**: ä¸»è¦AIæ¨ç†æœåŠ¡
   - ç«¯å£: 8000 (HTTP API), 50051 (gRPC)
   - ç¡¬ä»¶è®¿é—®: Hailo8 PCIe + NVIDIA GPU
   - è‡ªåŠ¨å¼•æ“é€‰æ‹©å’Œè´Ÿè½½å‡è¡¡

2. **redis**: ç¼“å­˜æœåŠ¡
   - ç«¯å£: 6379
   - ç”¨äºæ¨ç†ç»“æœç¼“å­˜å’Œæ€§èƒ½ä¼˜åŒ–

### ç¡¬ä»¶è¦æ±‚

- **Hailo8 PCIeåŠ é€Ÿå¡** (å¯é€‰)
- **NVIDIA GPU with CUDA** (å¯é€‰)
- **è‡³å°‘ä¸€ç§ç¡¬ä»¶å¯ç”¨**

## ğŸ“± APIæ¥å£

### åŸºç¡€ç«¯ç‚¹

```bash
# å¥åº·æ£€æŸ¥
curl http://localhost:8000/health

# ç¡¬ä»¶çŠ¶æ€
curl http://localhost:8000/ai/hardware

# å¯ç”¨å¼•æ“
curl http://localhost:8000/ai/engines
```

### æ¨ç†æ¥å£

```bash
# è‡ªåŠ¨é€‰æ‹©æœ€ä½³å¼•æ“
curl -X POST \
  -H "Content-Type: application/json" \
  -d '{
    "image": [[[255,0,0], [255,255,255], [255,0,0]]],
    "engine": "auto",
    "threshold": 0.4
  }' \
  http://localhost:8000/ai/infer

# å¼ºåˆ¶ä½¿ç”¨Hailo8
curl -X POST \
  -H "Content-Type: application/json" \
  -d '{
    "image": [[[255,0,0]]],
    "engine": "hailo"
  }' \
  http://localhost:8000/ai/infer

# å¼ºåˆ¶ä½¿ç”¨NVIDIA
curl -X POST \
  -H "Content-Type: application/json" \
  -d '{
    "image": [[[255,0,0]]],
    "engine": "nvidia"
  }' \
  http://localhost:8000/ai/infer
```

### é«˜çº§æ¨ç†æ¨¡å¼

```bash
# å¹¶è¡Œæ¨ç† (åŒæ—¶ä½¿ç”¨ä¸¤ä¸ªç¡¬ä»¶)
curl -X POST \
  -H "Content-Type: application/json" \
  -d '{
    "image": [[[255,0,0]]],
    "engine": "parallel",
    "priority": "performance"
  }' \
  http://localhost:8000/ai/infer

# åŒå¼•æ“èåˆ (é«˜ç²¾åº¦)
curl -X POST \
  -H "Content-Type: application/json" \
  -d '{
    "image": [[[255,0,0]]],
    "engine": "both",
    "priority": "accuracy"
  }' \
  http://localhost:8000/ai/infer

# è´Ÿè½½å‡è¡¡ (è‡ªåŠ¨ä¼˜åŒ–)
curl -X POST \
  -H "Content-Type: application/json" \
  -d '{
    "image": [[[255,0,0]]],
    "engine": "load_balance"
  }' \
  http://localhost:8000/ai/infer
```

## ğŸ¯ ä½¿ç”¨åœºæ™¯

### 1. å…¶ä»–å®¹å™¨è°ƒç”¨AIæœåŠ¡

æ‚¨çš„å…¶ä»–å®¹å™¨å¯ä»¥é€šè¿‡HTTP APIè°ƒç”¨AIæ¨ç†æœåŠ¡ï¼š

```python
import requests

# å‘é€æ¨ç†è¯·æ±‚
response = requests.post(
    'http://hailo8-ai:8000/ai/infer',
    json={
        'image': image_data,
        'engine': 'auto',
        'threshold': 0.5
    }
)

if response.status_code == 200:
    result = response.json()
    print(f"æ£€æµ‹åˆ° {len(result['detections'])} ä¸ªå¯¹è±¡")
    print(f"ä½¿ç”¨å¼•æ“: {result['engines_used']}")
```

### 2. ç¯å¢ƒå˜é‡é…ç½®

```yaml
# åœ¨å…¶ä»–å®¹å™¨çš„docker-compose.ymlä¸­
services:
  your-app:
    environment:
      - AI_SERVICE_URL=http://hailo8-ai:8000
      - AI_ENGINE=auto
```

## ğŸ“Š æ€§èƒ½ç›‘æ§

### æŸ¥çœ‹æœåŠ¡çŠ¶æ€

```bash
# æ£€æŸ¥å®¹å™¨çŠ¶æ€
docker ps | grep hailo8

# æŸ¥çœ‹èµ„æºä½¿ç”¨
docker stats hailo8-ai

# æŸ¥çœ‹ç¡¬ä»¶çŠ¶æ€
curl http://localhost:8000/ai/hardware | jq
```

### æ€§èƒ½åŸºå‡†

```bash
# è¿è¡Œæ€§èƒ½æµ‹è¯•
curl -X POST \
  -H "Content-Type: application/json" \
  -d '{"image":[[[255,0,0]]],"engine":"auto"}' \
  http://localhost:8000/ai/infer
```

## ğŸ› ï¸ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **ç¡¬ä»¶æœªè¢«æ£€æµ‹åˆ°**
   ```bash
   # æ£€æŸ¥Hailo8
   lspci | grep hailo
   ls -la /dev/hailo*

   # æ£€æŸ¥NVIDIA
   nvidia-smi
   ```

2. **å®¹å™¨å¯åŠ¨å¤±è´¥**
   ```bash
   # æŸ¥çœ‹è¯¦ç»†æ—¥å¿—
   docker-compose -f docker-compose.hailo8-nvidia.yml logs hailo8-ai

   # æ£€æŸ¥æƒé™
   ls -la /dev/hailo* /dev/nvidia*
   ```

3. **APIè°ƒç”¨å¤±è´¥**
   ```bash
   # æ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€
   curl http://localhost:8000/health

   # æ£€æŸ¥ç«¯å£
   netstat -tlnp | grep 8000
   ```

## ğŸ”„ ç»´æŠ¤æ“ä½œ

```bash
# é‡å¯æœåŠ¡
docker-compose -f docker-compose.hailo8-nvidia.yml restart

# æ›´æ–°é•œåƒ
docker-compose -f docker-compose.hailo8-nvidia.yml pull
docker-compose -f docker-compose.hailo8-nvidia.yml up -d

# åœæ­¢æœåŠ¡
docker-compose -f docker-compose.hailo8-nvidia.yml down

# æ¸…ç†èµ„æº
docker-compose -f docker-compose.hailo8-nvidia.yml down -v
```

## ğŸ“‚ ç›®å½•ç»“æ„

```
.
â”œâ”€â”€ docker-compose.hailo8-nvidia.yml    # ä¸»é…ç½®æ–‡ä»¶
â”œâ”€â”€ models/                            # AIæ¨¡å‹æ–‡ä»¶
â”œâ”€â”€ logs/                              # æ—¥å¿—æ–‡ä»¶
â””â”€â”€ hailo-runtime/                     # æœåŠ¡æºç 
    â”œâ”€â”€ Dockerfile
    â””â”€â”€ api/
        â”œâ”€â”€ enhanced_ai_acceleration_adapter.py
        â”œâ”€â”€ frigate_auto_discovery.py
        â””â”€â”€ main.py
```

## ğŸ‰ å®Œæˆï¼

ç°åœ¨æ‚¨æœ‰äº†ä¸€ä¸ªæ ‡å‡†çš„Docker Composeé…ç½®ï¼Œå¯ä»¥ä¸ºå…¶ä»–å®¹å™¨æä¾›Hailo8å’ŒNVIDIA AIåŠ é€ŸæœåŠ¡ã€‚å…¶ä»–å®¹å™¨åªéœ€é€šè¿‡HTTP APIå³å¯è°ƒç”¨AIæ¨ç†åŠŸèƒ½ã€‚