# Hailo8 + NVIDIA AIåŠ é€ŸæœåŠ¡æŒ‡å—

ğŸš€ **åŒç¡¬ä»¶AIæ¨ç†åŠ é€Ÿè§£å†³æ–¹æ¡ˆ**

## ğŸ“– æ¦‚è¿°

æœ¬æŒ‡å—æä¾›äº†ä½¿ç”¨Hailo8å’ŒNVIDIA GPUè¿›è¡ŒAIæ¨ç†åŠ é€Ÿçš„å®Œæ•´è§£å†³æ–¹æ¡ˆã€‚å®¹å™¨å†…çš„AIåŠ é€ŸæœåŠ¡å¯ä»¥åŒæ—¶æ”¯æŒHailo8 PCIeåŠ é€Ÿå¡å’ŒNVIDIA GPUï¼Œä¸ºå…¶ä»–å®¹å™¨æä¾›ç»Ÿä¸€çš„æ¨ç†APIæœåŠ¡ã€‚

## ğŸ¯ è§£å†³æ–¹æ¡ˆç‰¹ç‚¹

âœ… **åŒç¡¬ä»¶æ”¯æŒ**: åŒæ—¶æ”¯æŒHailo8å’ŒNVIDIA GPU
âœ… **è‡ªåŠ¨é€‰æ‹©**: æ ¹æ®å¯ç”¨æ€§è‡ªåŠ¨é€‰æ‹©æœ€ä½³æ¨ç†å¼•æ“
âœ… **ç»Ÿä¸€æ¥å£**: æä¾›ç»Ÿä¸€çš„APIæ¥å£ä¾›å…¶ä»–å®¹å™¨è°ƒç”¨
âœ… **ç¡¬ä»¶é€æ˜**: ä¸Šå±‚åº”ç”¨æ— éœ€å…³å¿ƒåº•å±‚ç¡¬ä»¶ç»†èŠ‚
âœ… **æ€§èƒ½ç›‘æ§**: å®æ—¶ç›‘æ§ç¡¬ä»¶ä½¿ç”¨æƒ…å†µå’Œæ¨ç†æ€§èƒ½
âœ… **è´Ÿè½½å‡è¡¡**: æ”¯æŒåœ¨å¤šä¸ªç¡¬ä»¶é—´è¿›è¡Œè´Ÿè½½å‡è¡¡

## ğŸ—ï¸ æ¶æ„è®¾è®¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  AIåŠ é€ŸæœåŠ¡å®¹å™¨                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚            ç»Ÿä¸€AIæ¨ç†API                           â”‚    â”‚
â”‚  â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚    â”‚
â”‚  â”‚        â”‚  å¼•æ“é€‰æ‹©å™¨  â”‚  â”‚   æ™ºèƒ½è°ƒåº¦å™¨      â”‚      â”‚    â”‚
â”‚  â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚    â”‚
â”‚  â”‚              â”‚                    â”‚                 â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚
â”‚  â”‚  â”‚  Hailo8 æ¨ç†å™¨  â”‚  â”‚ NVIDIAæ¨ç†ç®¡ç†å™¨  â”‚  â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚
â”‚  â”‚            â”‚                    â”‚                 â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚
â”‚  â”‚  â”‚    Hailo8ç¡¬ä»¶    â”‚  â”‚   NVIDIA GPU      â”‚  â”‚    â”‚
â”‚  â”‚  â”‚    (PCIeå¡)      â”‚  â”‚    (æ˜¾å¡)        â”‚  â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ï¿½  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼ HTTP/gRPC API
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  å…¶ä»–åº”ç”¨å®¹å™¨                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Frigate   â”‚  â”‚  Home      â”‚  â”‚   AIåº”ç”¨å®¹å™¨     â”‚  â”‚
â”‚  â”‚  (NVR)     â”‚  â”‚  Assistantâ”‚  â”‚                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ ç¡¬ä»¶è¦æ±‚

### åŸºæœ¬è¦æ±‚
- **Docker Engine**: 20.10+
- **Docker Compose**: 2.0+
- **Linuxç³»ç»Ÿ**: æ”¯æŒPCIeçš„Linuxå‘è¡Œç‰ˆ

### ç¡¬ä»¶è¦æ±‚ï¼ˆè‡³å°‘ä¸€ç§ï¼‰
- **Hailo8 PCIeåŠ é€Ÿå¡**:
  - Hailo8 PCIe x4æˆ–æ›´é«˜
  - æ”¯æŒçš„Linuxå†…æ ¸
  - è¶³å¤Ÿçš„PCIeå¸¦å®½å’Œç”µæºä¾›åº”

- **NVIDIA GPU**:
  - NVIDIA GPU (Pascalæ¶æ„æˆ–æ›´æ–°)
  - NVIDIAé©±åŠ¨ç‰ˆæœ¬ >= 470.xx
  - CUDA Toolkit >= 12.0
  - è¶³å¤Ÿçš„GPUå†…å­˜ï¼ˆå»ºè®®8GB+ï¼‰

### æ¨èé…ç½®
- **åŒç¡¬ä»¶ç¯å¢ƒ**: åŒæ—¶é…ç½®Hailo8å’ŒNVIDIA GPU
- **å†…å­˜**: 16GB+ (ç”¨äºæ¨¡å‹åŠ è½½å’Œæ¨ç†ç¼“å­˜)
- **å­˜å‚¨**: 100GB+ SSD
- **ç½‘ç»œ**: åƒå…†ç½‘ç»œè¿æ¥

## ğŸš€ å¿«é€Ÿéƒ¨ç½²

### 1. åŸºæœ¬éƒ¨ç½²

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/SunvidWong/hailo8.git
cd hailo8/containers

# å¯åŠ¨AIåŠ é€ŸæœåŠ¡
docker-compose -f docker-compose.ai-acceleration.yml up -d

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
docker-compose -f docker-compose.ai-acceleration.yml ps
```

### 2. éªŒè¯ç¡¬ä»¶

```bash
# æ£€æŸ¥å¯ç”¨ç¡¬ä»¶
curl http://localhost:8000/ai/hardware

# éªŒè¯ç¡¬ä»¶é…ç½®
curl -X POST http://localhost:8000/ai/validate
```

### 3. æµ‹è¯•æ¨ç†

```bash
# æ¨ç†å¼•æ“é€‰æ‹© (è‡ªåŠ¨)
curl -X POST \
  -H "Content-Type: application/json" \
  -d '{
    "image": [ [[255,0,0,255], [255,255,255], [255,0,0]]],
    "engine": "auto"
  }' \
  http://localhost:8000/ai/infer

# å¼ºåˆ¶ä½¿ç”¨Hailo8
curl -X POST \
  -H "Content-Type: application/json" \
  -d '{
    "image": [255,0,0,255,255,255,255,255,0,0]],
    "engine": "hailo",
    "threshold": 0.5
  }' \
  http://localhost:8000/ai/infer

# å¼ºåˆ¶ä½¿ç”¨NVIDIA
curl -X -X POST \
  -H "Content-Type: application/json" \
  -d '{
    "image": [255,0,0,255,255,255,255,255,0,0]],
    "engine": "nvidia",
    "threshold": 0.5
  }' \
  http://localhost:8000/ai/infer
```

## ğŸ“‹ APIæ¥å£è¯´æ˜

### æ ¸å¿ƒæ¥å£

#### 1. æ¨ç†æ¥å£
```http
POST /ai/infer
Content-Type: application/json

{
  "image": [
    [[255,0,0], [255,255,255], [255,0,0]]
  ],
  "engine": "auto",
  "model_name": "yolov8n",
  "threshold": 0.4,
  "targets": ["person", "car"]
}
```

#### 2. ç¡¬ä»¶ä¿¡æ¯æ¥å£
```http
GET /ai/hardware
```

å“åº”ç¤ºä¾‹:
```json
{
  "available_engines": ["hailo", "nvidia"],
  "hailo_devices": [
    {
      "id": 0,
      "name": "Hailo8 PCIe Device",
      "is_available": true,
      "device_id": "0000:00:01.0"
    }
  ],
  "nvidia_devices": [
    {
      "id": 0,
      "name": "NVIDIA GeForce RTX 4090",
      "memory_total": 24576,
      "memory_allocated": 2048,
      "is_available": true
    }
  ]
}
```

#### 3. å¼•æ“ä¿¡æ¯æ¥å£
```http
GET /ai/engines
```

#### 4. å¥åº·æ£€æŸ¥æ¥å£
```http
GET /ai/health
```

## ğŸ”§ é…ç½®é€‰é¡¹

### ç¯å¢ƒå˜é‡é…ç½®

```bash
# AIåŠ é€ŸæœåŠ¡é…ç½®
SUPPORT_HAILO=true              # å¯ç”¨Hailo8æ”¯æŒ
SUPPORT_NVIDIA=true            # å¯ç”¨NVIDIAæ”¯æŒ
DEFAULT_ENGINE=auto             # é»˜è®¤æ¨ç†å¼•æ“
FALLBACK_ENGINE=hailo           # å›é€€å¼•æ“
CACHE_ENABLED=true              # å¯ç”¨ç¼“å­˜
REDIS_URL=redis://redis:6379   # Redisè¿æ¥å­—ç¬¦ä¸²
```

### æ¨ç†å¼•æ“é…ç½®

#### è‡ªåŠ¨é€‰æ‹©æ¨¡å¼ (æ¨è)
```yaml
environment:
  - DEFAULT_ENGINE=auto
  - FALLBACK_ENGINE=hailo
```

- è‡ªåŠ¨é€‰æ‹©æœ€ä½³å¯ç”¨å¼•æ“
- ä¼˜å…ˆä½¿ç”¨NVIDIA GPU (æ€§èƒ½æ›´å¥½)
- å›é€€åˆ°Hailo8 (è¾¹ç¼˜æ¨ç†)

#### æ‰‹åŠ¨æŒ‡å®šæ¨¡å¼
```yaml
environment:
  - DEFAULT_ENGINE=nvidia  # å¼ºåˆ¶ä½¿ç”¨NVIDIA
  # æˆ–
  - DEFAULT_ENGINE=hailo   # å¼ºåˆ¶ä½¿ç”¨Hailo8
```

### æ€§èƒ½è°ƒä¼˜

#### Hailo8ä¼˜åŒ–
```yaml
environment:
  - HAILO_BATCH_SIZE=1          # æ‰¹å¤„ç†å¤§å°
  - HAILO_THREADS=2              # çº¿ç¨‹æ•°
  - HAILO_MEMORY_LIMIT=1024      # å†…å­˜é™åˆ¶(MB)
```

#### NVIDIAä¼˜åŒ–
```yaml
environment:
  - CUDA_VISIBLE_DEVICES=all    # å¯è§GPUè®¾å¤‡
  - NVIDIA_VISIBLE_DEVICES=all   # NVIDIAé©±åŠ¨æ”¯æŒ
  - TORCH_CUDA_ARCH_LIST=8.6       # CUDAæ¶æ„æ”¯æŒ
```

## ğŸ¯ ä½¿ç”¨åœºæ™¯

### 1. ä¸Frigateé›†æˆ

åœ¨Frigateé…ç½®ä¸­è®¾ç½®æ¨ç†æ£€æµ‹å™¨ï¼š

```yaml
# frigate config.yml
detectors:
  hailo8_detector:
    type: remote
    api:
      url: http://ai-acceleration-service:8000/ai/infer
      timeout: 5
      max_retries: 3
    threshold: 0.4
```

### 2. ä¸Home Assistanté›†æˆ

åœ¨Home Assistantä¸­æ·»åŠ APIè°ƒç”¨ï¼š

```yaml
# configuration.yaml
sensor:
  - platform: rest
    name: AI Inference Status
    resource: http://ai-acceleration-service:8000/ai/health
    value_template: "{{ value_json.status }}"
```

### 3. è‡ªå®šä¹‰AIåº”ç”¨

åœ¨æ‚¨çš„åº”ç”¨ä¸­è°ƒç”¨APIï¼š

```python
import requests

# å‘é€æ¨ç†è¯·æ±‚
response = requests.post(
    'http://ai-acceleration-service:8000/ai/infer',
    json={
        'image': image_data,
        'engine': 'auto',
        'threshold': 0.5
    }
)

if response.status_code == 200:
    result = response.json()
    print(f"æ£€æµ‹åˆ° {len(result['detections'])} ä¸ªå¯¹è±¡")
    print(f"ä½¿ç”¨å¼•æ“: {result['engine_used']}")
```

## ğŸ“Š ç›‘æ§å’Œç®¡ç†

### 1. æœåŠ¡ç›‘æ§

è®¿é—®åœ°å€ï¼š
- **Grafanaç›‘æ§**: http://localhost:3000
- **PrometheusæŒ‡æ ‡**: http://localhost:9090
- **æœåŠ¡çŠ¶æ€**: http://localhost:8000/ai/health

### 2. ç›‘æ§æŒ‡æ ‡

- æ¨ç†è¯·æ±‚æ€»æ•°å’Œå“åº”æ—¶é—´
- å„å¼•æ“ä½¿ç”¨æƒ…å†µ
- ç¡¬ä»¶åˆ©ç”¨ç‡
- é”™è¯¯ç‡å’Œæ•…éšœç»Ÿè®¡

### 3. æ—¥å¿—ç®¡ç†

```bash
# æŸ¥çœ‹æœåŠ¡æ—¥å¿—
docker-compose -f docker-compose.ai-acceleration.yml logs -f ai-acceleration-service

# æŸ¥çœ‹æ¨ç†æ—¥å¿—
tail -f logs/hailo/ai_service.log
```

### 4. æ€§èƒ½ä¼˜åŒ–

```bash
# è°ƒæ•´èµ„æºé…ç½®
vim docker-compose.ai-acceleration.yml

# é‡å¯æœåŠ¡
docker-compose -f docker-compose.ai-acceleration.yml restart
```

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. ç¡¬ä»¶æ£€æµ‹å¤±è´¥

**é—®é¢˜**: æœåŠ¡å¯åŠ¨æ—¶æ— æ³•æ£€æµ‹åˆ°ç¡¬ä»¶

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥Hailo8è®¾å¤‡
lspci | grep -i hailo
ls -la /dev/hailo*

# æ£€æŸ¥NVIDIAè®¾å¤‡
nvidia-smi
lspci | grep -i nvidia

# æ£€æŸ¥å†…æ ¸æ¨¡å—
lsmod | grep hailo
lsmod | grep nvidia
```

#### 2. æ¨ç†å¼•æ“é€‰æ‹©é—®é¢˜

**é—®é¢˜**: æ¨ç†å¼•æ“é€‰æ‹©ä¸ç¬¦åˆé¢„æœŸ

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥å¯ç”¨å¼•æ“
curl http://localhost:8000/ai/engines

# æ‰‹åŠ¨æŒ‡å®šå¼•æ“
curl -X POST http://localhost:8000/ai/infer \
  -H "Content-Type: application/json" \
  -d '{"image": [[[255,0,0]]], "engine": "hailo"}'
```

#### 3. å†…å­˜ä¸è¶³

**é—®é¢˜**: æ¨ç†å¤±è´¥ï¼Œæç¤ºå†…å­˜ä¸è¶³

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥å†…å­˜ä½¿ç”¨
docker stats ai-acceleration-service

# é‡Šæ”¾GPUå†…å­˜
nvidia-smi --gpu-reset

# è°ƒæ•´å®¹å™¨å†…å­˜é™åˆ¶
vim docker-compose.ai-acceleration.yml
```

#### 4. ç½‘ç»œè¿æ¥é—®é¢˜

**é—®é¢˜**: å…¶ä»–å®¹å™¨æ— æ³•è®¿é—®AIæœåŠ¡

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥ç½‘ç»œè¿æ¥
docker network ls

# æ£€æŸ¥å®¹å™¨ç½‘ç»œ
docker exec ai-aceration-service ping frigate

# éªŒè¯ç«¯å£æ˜ å°„
netstat -tlnp | grep 8000
```

### è°ƒè¯•æŠ€å·§

#### 1. å¯ç”¨è°ƒè¯•æ¨¡å¼
```yaml
environment:
  - DEBUG=true
  - LOG_LEVEL=DEBUG
```

#### 2. è¿›å…¥å®¹å™¨è°ƒè¯•
```bash
docker exec -it ai-acceleration-service bash
```

#### 3. æŸ¥çœ‹è¯¦ç»†æ—¥å¿—
```bash
docker-compose -f docker-compose.ai-acceleration.yml logs ai-acceleration-service
```

## ğŸ“š æ‰©å±•åŠŸèƒ½

### 1. å¤šå®ä¾‹éƒ¨ç½²

```yaml
services:
  ai-acceleration-service-1:
    # é…ç½®...

  ai-acceleration-service-2:
    # é…ç½®...
```

### 2. è´Ÿè½½å‡è¡¡

```yaml
environment:
  - LOAD_BALANCING=true
  - ROUND_ROBIN=true
```

### 3. ç¼“å­˜ä¼˜åŒ–

```yaml
services:
  redis:
    image: redis:7-alpine
    command: redis-server --maxmemory 2gb --maxmemory-policy allkeys-lru
```

## ğŸ‰ æ€»ç»“

ä½¿ç”¨Hailo8 + NVIDIAåŒç¡¬ä»¶åŠ é€ŸæœåŠ¡ï¼Œæ‚¨å¯ä»¥ï¼š

âœ… **æé«˜æ¨ç†æ€§èƒ½**: æ ¹æ®å·¥ä½œè´Ÿè½½è‡ªåŠ¨é€‰æ‹©æœ€ä½³ç¡¬ä»¶
âœ… **ç®€åŒ–åº”ç”¨å¼€å‘**: ä¸Šå±‚åº”ç”¨æ— éœ€å…³å¿ƒåº•å±‚ç¡¬ä»¶
âœ… **æé«˜ç¡¬ä»¶åˆ©ç”¨ç‡**: åŒæ—¶åˆ©ç”¨ä¸¤ç§åŠ é€Ÿå™¨
âœ… **å¢å¼ºç³»ç»Ÿå¯é æ€§**: ç¡¬ä»¶æ•…éšœæ—¶è‡ªåŠ¨åˆ‡æ¢
âœ… **é™ä½éƒ¨ç½²å¤æ‚åº¦**: ç»Ÿä¸€çš„APIæ¥å£ç®¡ç†

å¼€å§‹ä½¿ç”¨åŒç¡¬ä»¶AIåŠ é€ŸæœåŠ¡ï¼Œä½“éªŒæ›´å¼ºå¤§çš„AIæ¨ç†èƒ½åŠ›ï¼

---

ğŸš€ **ç°åœ¨æ‚¨å¯ä»¥å¼€å§‹éƒ¨ç½²åŒç¡¬ä»¶AIåŠ é€ŸæœåŠ¡äº†ï¼**

å¦‚æœ‰é—®é¢˜ï¼Œè¯·å‚è€ƒæ•…éšœæ’é™¤éƒ¨åˆ†æˆ–æŸ¥çœ‹å®Œæ•´æ–‡æ¡£ã€‚