# NVIDIAå®¹å™¨æ”¯æŒé…ç½®æŒ‡å—

## ğŸ¯ é—®é¢˜è¯´æ˜

æ‚¨æŒ‡å‡ºçš„é—®é¢˜éå¸¸æ­£ç¡®ï¼ä¹‹å‰çš„é…ç½®ç¼ºå°‘äº†NVIDIAå®¹å™¨åœ¨Dockerä¸­è¿è¡Œçš„å…³é”®é…ç½®ã€‚è¦è®©NVIDIAæ˜¾å¡åœ¨å®¹å™¨ä¸­æ­£å¸¸å·¥ä½œï¼Œéœ€è¦æ­£ç¡®é…ç½®NVIDIA Container Toolkitã€‚

## ğŸ”§ å‰ç½®è¦æ±‚

### 1. ç³»ç»Ÿè¦æ±‚
- **Linuxç³»ç»Ÿ**: Ubuntu 20.04+ / CentOS 8+ / RHEL 8+
- **å†…æ ¸ç‰ˆæœ¬**: 4.15+
- **NVIDIAé©±åŠ¨**: 470.xx+ (æ¨è 515.xx+)
- **Docker Engine**: 20.10+
- **NVIDIA Container Toolkit**: æœ€æ–°ç‰ˆæœ¬

### 2. ç¡¬ä»¶è¦æ±‚
- **NVIDIA GPU**: Pascalæ¶æ„æˆ–æ›´æ–°
- **Hailo8 PCIeå¡**: å¯é€‰ï¼Œç”¨äºåŒç¡¬ä»¶åŠ é€Ÿ

## ğŸš€ NVIDIAå®¹å™¨æ”¯æŒå®‰è£…æ­¥éª¤

### æ­¥éª¤1: å®‰è£…NVIDIAé©±åŠ¨
```bash
# Ubuntu/Debian
sudo apt update
sudo apt install nvidia-driver-515 nvidia-cuda-toolkit

# éªŒè¯é©±åŠ¨å®‰è£…
nvidia-smi
```

### æ­¥éª¤2: å®‰è£…NVIDIA Container Toolkit
```bash
# æ·»åŠ NVIDIAä»“åº“
curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list

# å®‰è£…toolkit
sudo apt update
sudo apt install -y nvidia-container-toolkit

# é…ç½®Dockerè¿è¡Œæ—¶
sudo nvidia-ctk runtime configure --runtime=docker
sudo systemctl restart docker
```

### æ­¥éª¤3: éªŒè¯NVIDIAå®¹å™¨æ”¯æŒ
```bash
# æµ‹è¯•NVIDIAå®¹å™¨
docker run --rm --gpus all nvidia/cuda:12.1.0-base-ubuntu22.04 nvidia-smi

# åº”è¯¥æ˜¾ç¤ºGPUä¿¡æ¯ï¼Œè€Œä¸æ˜¯é”™è¯¯
```

## ğŸ“‹ æ­£ç¡®çš„Docker Composeé…ç½®

### å…³é”®é…ç½®è¦ç´ 

1. **GPUè®¾å¤‡åˆ†é…**:
```yaml
deploy:
  resources:
    reservations:
      devices:
        - driver: nvidia
          count: all
          capabilities: [gpu]
```

2. **ç¯å¢ƒå˜é‡**:
```yaml
environment:
  - NVIDIA_VISIBLE_DEVICES=all
  - NVIDIA_DRIVER_CAPABILITIES=compute,utility
  - CUDA_VISIBLE_DEVICES=all
  - CUDA_MODULE_LOADING=LAZY
```

3. **åŸºç¡€é•œåƒé€‰æ‹©**:
```dockerfile
FROM nvidia/cuda:12.1.0-runtime-ubuntu22.04
```

## ğŸ” éªŒè¯é…ç½®

### æ£€æŸ¥NVIDIAæ”¯æŒ
```bash
# å¯åŠ¨æœåŠ¡
docker-compose -f docker-compose.nvidia-fixed.yml up -d

# è¿›å…¥å®¹å™¨æ£€æŸ¥GPU
docker exec -it hailo8-ai nvidia-smi

# æ£€æŸ¥CUDA
docker exec -it hailo8-ai python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
```

### APIæµ‹è¯•
```bash
# æ£€æŸ¥ç¡¬ä»¶çŠ¶æ€
curl http://localhost:8000/ai/hardware

# åº”è¯¥çœ‹åˆ°ç±»ä¼¼è¾“å‡º:
{
  "available_engines": ["hailo", "nvidia"],
  "nvidia_devices": [
    {
      "id": 0,
      "name": "NVIDIA GeForce RTX 4090",
      "memory_total": 24576,
      "memory_allocated": 0
    }
  ]
}
```

## âš ï¸ å¸¸è§é—®é¢˜

### 1. "Could not select device driver"
**åŸå› **: NVIDIA Container Toolkitæœªæ­£ç¡®å®‰è£…
**è§£å†³**: é‡æ–°å®‰è£…NVIDIA Container Toolkit

### 2. "CUDA runtime error"
**åŸå› **: CUDAç‰ˆæœ¬ä¸åŒ¹é…æˆ–é©±åŠ¨ç‰ˆæœ¬è¿‡ä½
**è§£å†³**: æ›´æ–°NVIDIAé©±åŠ¨åˆ°æœ€æ–°ç‰ˆæœ¬

### 3. "GPUå†…å­˜ä¸è¶³"
**åŸå› **: GPUå†…å­˜è¢«å…¶ä»–è¿›ç¨‹å ç”¨
**è§£å†³**: æ£€æŸ¥GPUä½¿ç”¨æƒ…å†µå¹¶é‡Šæ”¾å†…å­˜

### 4. "æƒé™è¢«æ‹’ç»"
**åŸå› **: ç”¨æˆ·ä¸åœ¨dockerç»„ä¸­
**è§£å†³**:
```bash
sudo usermod -aG docker $USER
# é‡æ–°ç™»å½•æˆ–æ‰§è¡Œ newgrp docker
```

## ğŸ¯ å®Œæ•´éƒ¨ç½²æµç¨‹

```bash
# 1. æ£€æŸ¥ç³»ç»Ÿè¦æ±‚
nvidia-smi
docker --version

# 2. å®‰è£…NVIDIA Container Toolkit (å¦‚æœæœªå®‰è£…)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list
sudo apt update && sudo apt install -y nvidia-docker2
sudo systemctl restart docker

# 3. éªŒè¯å®¹å™¨æ”¯æŒ
docker run --rm --gpus all nvidia/cuda:12.1.0-base nvidia-smi

# 4. å¯åŠ¨AIåŠ é€ŸæœåŠ¡
docker-compose -f docker-compose.nvidia-fixed.yml up -d

# 5. éªŒè¯æœåŠ¡
curl http://localhost:8000/ai/hardware
```

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### GPUå†…å­˜ç®¡ç†
```yaml
environment:
  - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128
  - CUDA_LAUNCH_BLOCKING=1  # è°ƒè¯•æ—¶ä½¿ç”¨
```

### æ‰¹å¤„ç†ä¼˜åŒ–
```yaml
environment:
  - TORCH_CUDA_ARCH_LIST="8.6"  # æ ¹æ®GPUæ¶æ„è°ƒæ•´
  - CUDA_VISIBLE_DEVICES=0      # æŒ‡å®šä½¿ç”¨å“ªå—GPU
```

## ğŸ‰ æ€»ç»“

ç°åœ¨é…ç½®å·²ç»æ­£ç¡®æ”¯æŒNVIDIAå®¹å™¨ï¼š

âœ… **æ­£ç¡®å®‰è£…NVIDIA Container Toolkit**
âœ… **ä½¿ç”¨deploy.resources.reservationsé…ç½®GPU**
âœ… **è®¾ç½®æ­£ç¡®çš„NVIDIAç¯å¢ƒå˜é‡**
âœ… **ä½¿ç”¨NVIDIA CUDAåŸºç¡€é•œåƒ**
âœ… **å®Œæ•´çš„å¥åº·æ£€æŸ¥å’ŒéªŒè¯æµç¨‹**

è¿™æ ·NVIDIAæ˜¾å¡å°±èƒ½åœ¨å®¹å™¨ä¸­æ­£å¸¸å·¥ä½œï¼Œä¸Hailo8ä¸€èµ·æä¾›åŒç¡¬ä»¶AIåŠ é€ŸæœåŠ¡ï¼