# Hailo8 + NVIDIA AIåŠ é€ŸæœåŠ¡

ğŸš€ **åŒç¡¬ä»¶AIæ¨ç†åŠ é€Ÿè§£å†³æ–¹æ¡ˆ - Docker Composeå®¹å™¨åŒ–éƒ¨ç½²**

## ğŸ“– é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®æä¾›äº†ä¸€å¥—å®Œæ•´çš„Hailo8 PCIe + NVIDIA GPUåŒç¡¬ä»¶AIæ¨ç†åŠ é€Ÿè§£å†³æ–¹æ¡ˆï¼Œé€šè¿‡Docker Composeå®¹å™¨åŒ–éƒ¨ç½²ï¼Œä¸ºå…¶ä»–å®¹å™¨æä¾›ç»Ÿä¸€çš„AIæ¨ç†APIæœåŠ¡ã€‚

![æ¶æ„å›¾](https://maas-log-prod.cn-wlcb.ufileos.com/anthropic/37cb952e-bf22-45fb-ab90-1bf74ce56b5c/19bca8642cc000fb1b8dec3a39b7f842.jpg?UCloudPublicKey=TOKEN_e15ba47a-d098-4fbd-9afc-a0dcf0e4e621&Expires=1759715004&Signature=sJPoOSljpc0B+A04yf9aqWNhXug=)

## ğŸ¯ éƒ¨ç½²æ–¹æ¡ˆ

### æ–¹æ¡ˆä¸€ï¼šå®¹å™¨åŒ–AIæ¨ç†æœåŠ¡ï¼ˆæ¨èï¼‰â­

**ä½¿ç”¨Docker Composeéƒ¨ç½²å®¹å™¨ï¼Œä¸ºå…¶ä»–å®¹å™¨æä¾›AIæ¨ç†åŠ é€ŸAPI**

#### ğŸ“‹ å‰ç½®è¦æ±‚

**ç¡¬ä»¶è¦æ±‚ï¼š**
- **Hailo8 PCIeåŠ é€Ÿå¡** (å¯é€‰)
- **NVIDIA GPU** (å¯é€‰)
- **è‡³å°‘ä¸€ç§ç¡¬ä»¶å¯ç”¨**

**ç³»ç»Ÿè¦æ±‚ï¼š**
- **Linuxç³»ç»Ÿ** (Ubuntu 20.04+, CentOS 8+, RHEL 8+)
- **å†…æ ¸ç‰ˆæœ¬**: 4.15+
- **Docker Engine**: 20.10+
- **NVIDIA Container Toolkit** (å¦‚æœä½¿ç”¨NVIDIA GPU)

#### ğŸš€ 5åˆ†é’Ÿå¿«é€Ÿéƒ¨ç½²

```bash
# 1. å…‹éš†é¡¹ç›®
git clone https://github.com/SunvidWong/hailo8.git
cd hailo8/containers

# 2. å®‰è£…NVIDIA Container Toolkit (ä»…NVIDIAç”¨æˆ·)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list
sudo apt update && sudo apt install -y nvidia-docker2
sudo systemctl restart docker

# 3. éªŒè¯NVIDIAæ”¯æŒ (ä»…NVIDIAç”¨æˆ·)
docker run --rm --gpus all nvidia/cuda:12.1.0-base nvidia-smi

# 4. å¯åŠ¨AIåŠ é€ŸæœåŠ¡
docker-compose -f docker-compose.official.yml up -d

# 5. éªŒè¯éƒ¨ç½²
curl http://localhost:8000/health
curl http://localhost:8000/ai/hardware
```

#### ğŸ“± æœåŠ¡è®¿é—®

| æœåŠ¡ | åœ°å€ | ç”¨é€” |
|------|------|------|
| **AIæ¨ç†API** | http://localhost:8000 | ä¸»è¦APIæœåŠ¡ |
| **APIæ–‡æ¡£** | http://localhost:8000/docs | Swaggeræ–‡æ¡£ |
| **Redisç¼“å­˜** | localhost:6379 | ç¼“å­˜æœåŠ¡ |

#### ğŸ”§ APIè°ƒç”¨ç¤ºä¾‹

```bash
# æ£€æŸ¥ç¡¬ä»¶çŠ¶æ€
curl http://localhost:8000/ai/hardware

# è‡ªåŠ¨æ¨ç† (æ™ºèƒ½é€‰æ‹©ç¡¬ä»¶)
curl -X POST \
  -H "Content-Type: application/json" \
  -d '{
    "image": [[[255,0,0], [255,255,255], [255,0,0]]],
    "engine": "auto",
    "threshold": 0.4
  }' \
  http://localhost:8000/ai/infer

# å¼ºåˆ¶ä½¿ç”¨NVIDIA
curl -X POST \
  -H "Content-Type: application/json" \
  -d '{
    "image": [[[255,0,0]]],
    "engine": "nvidia"
  }' \
  http://localhost:8000/ai/infer

# å¼ºåˆ¶ä½¿ç”¨Hailo8
curl -X POST \
  -H "Content-Type: application/json" \
  -d '{
    "image": [[[255,0,0]]],
    "engine": "hailo"
  }' \
  http://localhost:8000/ai/infer
```

#### ğŸ›ï¸ é«˜çº§æ¨ç†æ¨¡å¼

```bash
# å¹¶è¡Œæ¨ç† (åŒæ—¶ä½¿ç”¨ä¸¤ä¸ªç¡¬ä»¶)
curl -X POST \
  -H "Content-Type: application/json" \
  -d '{
    "image": [[[255,0,0]]],
    "engine": "parallel",
    "priority": "performance"
  }' \
  http://localhost:8000/ai/infer

# åŒå¼•æ“èåˆ (é«˜ç²¾åº¦)
curl -X POST \
  -H "Content-Type: application/json" \
  -d '{
    "image": [[[255,0,0]]],
    "engine": "both",
    "priority": "accuracy"
  }' \
  http://localhost:8000/ai/inver

# è´Ÿè½½å‡è¡¡ (è‡ªåŠ¨ä¼˜åŒ–)
curl -X POST \
  -H "Content-Type: application/json" \
  -d '{
    "image": [[[255,0,0]]],
    "engine": "load_balance"
  }' \
  http://localhost:8000/ai/infer
```

#### ğŸ³ å…¶ä»–å®¹å™¨è°ƒç”¨ç¤ºä¾‹

```python
# å…¶ä»–å®¹å™¨ä¸­è°ƒç”¨AIæœåŠ¡
import requests

def ai_inference(image_data, engine="auto"):
    response = requests.post(
        'http://hailo8-ai:8000/ai/infer',
        json={
            'image': image_data,
            'engine': engine,
            'threshold': 0.5
        }
    )

    if response.status_code == 200:
        result = response.json()
        print(f"æ£€æµ‹åˆ° {len(result['detections'])} ä¸ªå¯¹è±¡")
        print(f"ä½¿ç”¨å¼•æ“: {result['engines_used']}")
        print(f"æ¨ç†æ—¶é—´: {result['inference_time']:.3f}s")
        return result
    else:
        print(f"æ¨ç†å¤±è´¥: {response.text}")
        return None

# ä½¿ç”¨ç¤ºä¾‹
result = ai_inference(your_image_data)
```

#### ğŸ“Š Docker Composeé…ç½®è¯¦è§£

```yaml
# docker-compose.official.yml
services:
  hailo8-ai:
    build:
      context: ./hailo-runtime
      args:
        SUPPORT_NVIDIA: "true"
        SUPPORT_HAILO: "true"

    # NVIDIA GPUæ”¯æŒ
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

    ports:
      - "8000:8000"

    volumes:
      - ./models:/app/models
      - /dev/hailo0:/dev/hailo0
      - /dev/dri:/dev/dri

    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - CUDA_VISIBLE_DEVICES=all
      - DEFAULT_ENGINE=auto
```

#### ğŸ” éªŒè¯å’Œæµ‹è¯•

```bash
# è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶
./test_ai_acceleration.sh

# æ‰‹åŠ¨æµ‹è¯•ç¡¬ä»¶æ£€æµ‹
curl http://localhost:8000/ai/hardware | jq

# æµ‹è¯•å„å¼•æ“æ€§èƒ½
curl -X POST -H "Content-Type: application/json" \
  -d '{"image":[[[255,0,0]]],"engine":"auto"}' \
  http://localhost:8000/ai/infer
```

---

### æ–¹æ¡ˆäºŒï¼šHailo8 PCIeå¡é©±åŠ¨å®‰è£…

**ç›´æ¥åœ¨å®¿ä¸»æœºå®‰è£…Hailo8é©±åŠ¨ï¼Œé€‚ç”¨äºéå®¹å™¨åŒ–éƒ¨ç½²**

#### ç³»ç»Ÿè¦æ±‚
- Linux (Ubuntu 18.04+, Debian 9+, CentOS 7+, RHEL 7+)
- å†…æ ¸ç‰ˆæœ¬ 4.0+
- rootæƒé™
- è‡³å°‘ 2GB å¯ç”¨ç©ºé—´

#### å®‰è£…æ­¥éª¤
```bash
# 1. å‡†å¤‡ç¯å¢ƒ
sudo su
cd hailo8/installer

# 2. æ‰§è¡Œå®‰è£…
python3 hailo8_installer.py

# 3. éªŒè¯å®‰è£…
ls -la /dev/hailo*
```

---

### æ–¹æ¡ˆä¸‰ï¼šNVIDIA Dockerç¯å¢ƒ

**é…ç½®NVIDIA Container Toolkitï¼Œä¸ºå®¹å™¨æä¾›GPUæ”¯æŒ**

#### å®‰è£…é…ç½®
```bash
# å®‰è£…NVIDIA Container Toolkit
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add
sudo apt install -y nvidia-docker2
sudo systemctl restart docker

# éªŒè¯GPUå®¹å™¨æ”¯æŒ
docker run --rm --gpus all nvidia/cuda:12.1.0-base nvidia-smi
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
hailo8/
â”œâ”€â”€ ğŸ“¦ containers/                    # æ–¹æ¡ˆä¸€ï¼šå®¹å™¨åŒ–æœåŠ¡
â”‚   â”œâ”€â”€ docker-compose.official.yml  # Dockerå®˜æ–¹è§„èŒƒé…ç½®
â”‚   â”œâ”€â”€ docker-compose.nvidia-fixed.yml # NVIDIAä¿®æ­£ç‰ˆ
â”‚   â”œâ”€â”€ README_STANDARD.md           # æ ‡å‡†é…ç½®è¯´æ˜
â”‚   â”œâ”€â”€ NVIDIA_CONTAINER_SETUP.md    # NVIDIAå®¹å™¨é…ç½®æŒ‡å—
â”‚   â”œâ”€â”€ DOCKER_COMPOSE_SPEC.md       # Dockerè§„èŒƒè¯´æ˜
â”‚   â”œâ”€â”€ AI_ACCELERATION_GUIDE.md     # å®Œæ•´ä½¿ç”¨æŒ‡å—
â”‚   â”œâ”€â”€ ENGINE_SELECTION_GUIDE.md     # å¼•æ“é€‰æ‹©æŒ‡å—
â”‚   â”œâ”€â”€ ZERO_CONFIG_GUIDE.md         # é›¶é…ç½®éƒ¨ç½²æŒ‡å—
â”‚   â”œâ”€â”€ test_ai_acceleration.sh      # å®Œæ•´æµ‹è¯•è„šæœ¬
â”‚   â””â”€â”€ ğŸ“ hailo-runtime/            # AIæœåŠ¡æºç 
â”‚       â”œâ”€â”€ Dockerfile              # å®¹å™¨é•œåƒæ„å»º
â”‚       â”œâ”€â”€ api/                    # APIæœåŠ¡ä»£ç 
â”‚       â”‚   â”œâ”€â”€ enhanced_ai_acceleration_adapter.py
â”‚       â”‚   â”œâ”€â”€ frigate_auto_discovery.py
â”‚       â”‚   â””â”€â”€ main.py
â”‚       â””â”€â”€ scripts/                # éƒ¨ç½²è„šæœ¬
â”œâ”€â”€ ğŸ”§ installer/                    # æ–¹æ¡ˆäºŒï¼šé©±åŠ¨å®‰è£…
â”‚   â”œâ”€â”€ hailo8_installer.py         # æ™ºèƒ½å®‰è£…ç®¡ç†å™¨
â”‚   â”œâ”€â”€ install_hailo8_onekey.sh    # ä¸€é”®å®‰è£…è„šæœ¬
â”‚   â””â”€â”€ README_INSTALLER.md         # å®‰è£…å™¨è¯´æ˜
â””â”€â”€ ğŸ“š docs/                        # æ–‡æ¡£ç›®å½•
    â”œâ”€â”€ INSTALL_GUIDE.md             # å®‰è£…æŒ‡å—
    â”œâ”€â”€ TROUBLESHOOTING.md          # æ•…éšœæ’é™¤
    â””â”€â”€ API_REFERENCE.md            # APIå‚è€ƒ
```

## ğŸ”§ é…ç½®è¯´æ˜

### ç¯å¢ƒå˜é‡é…ç½®

| å˜é‡å | é»˜è®¤å€¼ | è¯´æ˜ |
|--------|--------|------|
| `SUPPORT_HAILO` | `true` | å¯ç”¨Hailo8æ”¯æŒ |
| `SUPPORT_NVIDIA` | `true` | å¯ç”¨NVIDIAæ”¯æŒ |
| `DEFAULT_ENGINE` | `auto` | é»˜è®¤æ¨ç†å¼•æ“ |
| `LOG_LEVEL` | `INFO` | æ—¥å¿—çº§åˆ« |

### æ¨ç†å¼•æ“é€‰æ‹©

| å¼•æ“ | é€‚ç”¨åœºæ™¯ | ä¼˜åŠ¿ |
|------|----------|------|
| `auto` | é€šç”¨åœºæ™¯ | è‡ªåŠ¨é€‰æ‹©æœ€ä½³ç¡¬ä»¶ |
| `hailo` | è¾¹ç¼˜æ¨ç† | ä½åŠŸè€—ã€ä½å»¶è¿Ÿ |
| `nvidia` | é«˜ç²¾åº¦æ¨ç† | é«˜ç®—åŠ›ã€å¤æ‚æ¨¡å‹ |
| `both` | é«˜ç²¾åº¦éœ€æ±‚ | åŒå¼•æ“èåˆ |
| `parallel` | é«˜ååé‡ | å¹¶è¡Œå¤„ç† |
| `load_balance` | ç”Ÿäº§ç¯å¢ƒ | è´Ÿè½½å‡è¡¡ |

## ğŸ“Š ç›‘æ§å’Œè¿ç»´

### æœåŠ¡çŠ¶æ€æ£€æŸ¥
```bash
# æ£€æŸ¥å®¹å™¨çŠ¶æ€
docker-compose -f docker-compose.official.yml ps

# æŸ¥çœ‹å®æ—¶æ—¥å¿—
docker-compose -f docker-compose.official.yml logs -f hailo8-ai

# æ£€æŸ¥ç¡¬ä»¶çŠ¶æ€
curl http://localhost:8000/ai/hardware
```

### æ€§èƒ½ç›‘æ§
```bash
# æŸ¥çœ‹GPUä½¿ç”¨æƒ…å†µ (NVIDIA)
nvidia-smi

# æŸ¥çœ‹æœåŠ¡èµ„æºä½¿ç”¨
docker stats hailo8-ai

# APIæ€§èƒ½æµ‹è¯•
curl -X POST -H "Content-Type: application/json" \
  -d '{"image":[[[255,0,0]]],"engine":"auto"}' \
  http://localhost:8000/ai/infer
```

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. NVIDIAå®¹å™¨é—®é¢˜
```bash
# æ£€æŸ¥NVIDIAé©±åŠ¨
nvidia-smi

# éªŒè¯å®¹å™¨æ”¯æŒ
docker run --rm --gpus all nvidia/cuda:12.1.0-base nvidia-smi

# é‡æ–°å®‰è£…NVIDIA Container Toolkit
sudo apt purge nvidia-docker2
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add
sudo apt install -y nvidia-docker2
sudo systemctl restart docker
```

#### 2. Hailo8è®¾å¤‡é—®é¢˜
```bash
# æ£€æŸ¥PCIeè®¾å¤‡
lspci | grep hailo

# æ£€æŸ¥è®¾å¤‡èŠ‚ç‚¹
ls -la /dev/hailo*

# æ£€æŸ¥é©±åŠ¨åŠ è½½
lsmod | grep hailo

# æŸ¥çœ‹å†…æ ¸æ—¥å¿—
dmesg | grep hailo
```

#### 3. å®¹å™¨å¯åŠ¨é—®é¢˜
```bash
# æŸ¥çœ‹è¯¦ç»†é”™è¯¯æ—¥å¿—
docker-compose -f docker-compose.official.yml logs hailo8-ai

# é‡æ–°æ„å»ºé•œåƒ
docker-compose -f docker-compose.official.yml build --no-cache

# æ£€æŸ¥æƒé™é—®é¢˜
sudo usermod -aG docker $USER
newgrp docker
```

## ğŸ¯ ä½¿ç”¨åœºæ™¯

### 1. æ™ºèƒ½æ‘„åƒå¤´ç³»ç»Ÿ
```python
# æ‘„åƒå¤´å®¹å™¨è°ƒç”¨AIæœåŠ¡
def process_camera_frame(frame_data):
    result = requests.post(
        'http://hailo8-ai:8000/ai/infer',
        json={
            'image': frame_data,
            'engine': 'auto',
            'threshold': 0.5
        }
    )
    return result.json()
```

### 2. å®æ—¶è§†é¢‘åˆ†æ
```python
# è§†é¢‘æµå¤„ç†å®¹å™¨
import cv2
import requests

cap = cv2.VideoCapture(0)
while True:
    ret, frame = cap.read()
    if ret:
        # å‘é€å¸§åˆ°AIæœåŠ¡
        result = ai_inference(frame.tolist())
        # å¤„ç†æ£€æµ‹ç»“æœ...
```

### 3. æ‰¹é‡å›¾åƒå¤„ç†
```python
# æ‰¹é‡å¤„ç†æœåŠ¡å®¹å™¨
def batch_process_images(image_paths):
    for path in image_paths:
        with open(path, 'rb') as f:
            image_data = f.read()
        result = ai_inference(image_data)
        # ä¿å­˜ç»“æœ...
```

## ğŸ¤ è´¡çŒ®æŒ‡å—

1. Forké¡¹ç›®
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. å‘èµ·Pull Request

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ª MIT è®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…ã€‚

## ğŸ“ æŠ€æœ¯æ”¯æŒ

- ğŸ› é—®é¢˜åé¦ˆ: [GitHub Issues](https://github.com/SunvidWong/hailo8/issues)
- ğŸ“– å®Œæ•´æ–‡æ¡£: [containers/README_STANDARD.md](containers/README_STANDARD.md)
- ğŸ”§ è¯¦ç»†é…ç½®: [containers/AI_ACCELERATION_GUIDE.md](containers/AI_ACCELERATION_GUIDE.md)

---

ğŸ‰ **æ„Ÿè°¢ä½¿ç”¨Hailo8 + NVIDIA AIåŠ é€ŸæœåŠ¡ï¼**

ğŸŒŸ å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·ç»™å®ƒä¸€ä¸ªâ­ï¸